"use strict";(self.webpackChunkmind_mash=self.webpackChunkmind_mash||[]).push([[3885],{11506:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>o,toc:()=>c});var t=i(74848),a=i(28453);const s={id:"google-2-unit-addtional-1",title:"\ud83d\udcd6 Gradient Descent"},r=void 0,o={id:"notes/Information Technology/Artificial Intelligence/\ud83d\udc68\ud83c\udffb\u200d\ud83c\udfeb Google - 02 - ML/google-2-unit-addtional-1",title:"\ud83d\udcd6 Gradient Descent",description:"\u27a1\ufe0f Useful Materials",source:"@site/docs/notes/Information Technology/Artificial Intelligence/\ud83d\udc68\ud83c\udffb\u200d\ud83c\udfeb Google - 02 - ML/02_unit_additional_gradient-descent.md",sourceDirName:"notes/Information Technology/Artificial Intelligence/\ud83d\udc68\ud83c\udffb\u200d\ud83c\udfeb Google - 02 - ML",slug:"/notes/Information Technology/Artificial Intelligence/\ud83d\udc68\ud83c\udffb\u200d\ud83c\udfeb Google - 02 - ML/google-2-unit-addtional-1",permalink:"/MindMash/docs/notes/Information Technology/Artificial Intelligence/\ud83d\udc68\ud83c\udffb\u200d\ud83c\udfeb Google - 02 - ML/google-2-unit-addtional-1",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:2,frontMatter:{id:"google-2-unit-addtional-1",title:"\ud83d\udcd6 Gradient Descent"},sidebar:"notesSidebar",previous:{title:"\ud83d\udcd6 Linear Regression",permalink:"/MindMash/docs/notes/Information Technology/Artificial Intelligence/\ud83d\udc68\ud83c\udffb\u200d\ud83c\udfeb Google - 02 - ML/google-2-unit-1"},next:{title:"\ud83d\udcd6 Logistic Regression",permalink:"/MindMash/docs/notes/Information Technology/Artificial Intelligence/\ud83d\udc68\ud83c\udffb\u200d\ud83c\udfeb Google - 02 - ML/google-2-unit-2"}},l={},c=[{value:"\u27a1\ufe0f <strong>Useful Materials</strong>",id:"\ufe0f-useful-materials",level:2},{value:"Original Source",id:"original-source",level:3},{value:"Resources and Further Study",id:"resources-and-further-study",level:3},{value:"1\ufe0f\u20e3 <strong>Background and Motivation</strong>",id:"1\ufe0f\u20e3-background-and-motivation",level:2},{value:"Handwritten Digit Recognition",id:"handwritten-digit-recognition",level:3},{value:"Network Architecture Recap",id:"network-architecture-recap",level:3},{value:"Parameters (Weights and Biases)",id:"parameters-weights-and-biases",level:3},{value:"2\ufe0f\u20e3 <strong>The Learning Goal: Minimizing Cost</strong>",id:"2\ufe0f\u20e3-the-learning-goal-minimizing-cost",level:2},{value:"1. Define a Cost Function",id:"1-define-a-cost-function",level:3},{value:"2. Average Over the Entire Training Set",id:"2-average-over-the-entire-training-set",level:3},{value:"3. Local Minima vs. Global Minima",id:"3-local-minima-vs-global-minima",level:3},{value:"3\ufe0f\u20e3 <strong>The Core Algorithm: Gradient Descent</strong>",id:"3\ufe0f\u20e3-the-core-algorithm-gradient-descent",level:2},{value:"Key Idea",id:"key-idea",level:3},{value:"Backpropagation",id:"backpropagation",level:3},{value:"4\ufe0f\u20e3 <strong>Performance and Observations</strong>",id:"4\ufe0f\u20e3-performance-and-observations",level:2},{value:"Accuracy on New Data",id:"accuracy-on-new-data",level:3},{value:"Hidden Layer Interpretations",id:"hidden-layer-interpretations",level:3},{value:"Overconfidence on Garbage Inputs",id:"overconfidence-on-garbage-inputs",level:3},{value:"5\ufe0f\u20e3 <strong>Local Minima and \u201cMemorization\u201d in Modern DL</strong>",id:"5\ufe0f\u20e3-local-minima-and-memorization-in-modern-dl",level:2},{value:"Local Minima as Valleys",id:"local-minima-as-valleys",level:3},{value:"Structured vs. Random Labels",id:"structured-vs-random-labels",level:3},{value:"Implications",id:"implications",level:3},{value:"6\ufe0f\u20e3 <strong>Beyond the Basics</strong>",id:"6\ufe0f\u20e3-beyond-the-basics",level:2},{value:"Why Continuous Activations?",id:"why-continuous-activations",level:3},{value:"Scaling Up",id:"scaling-up",level:3},{value:"7\ufe0f\u20e3 <strong>Conclusion</strong>",id:"7\ufe0f\u20e3-conclusion",level:2}];function d(e){const n={annotation:"annotation",br:"br",em:"em",h2:"h2",h3:"h3",li:"li",math:"math",mo:"mo",mrow:"mrow",ol:"ol",p:"p",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(n.h2,{id:"\ufe0f-useful-materials",children:["\u27a1\ufe0f ",(0,t.jsx)(n.strong,{children:"Useful Materials"})]}),"\n",(0,t.jsx)(n.h3,{id:"original-source",children:"Original Source"}),"\n",(0,t.jsx)(n.p,{children:"For a more in-depth explanation of Gradient Descent, we recommend the following video by 3Blue1Brown."}),"\n",(0,t.jsx)("iframe",{src:"https://www.youtube.com/embed/IHZwWFHWa-w",title:"Gradient descent, how neural networks learn | DL2",frameBorder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowFullScreen:!0,className:"video-holidays"}),"\n",(0,t.jsx)(n.h3,{id:"resources-and-further-study",children:"Resources and Further Study"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Michael Nielsen\u2019s online book on neural networks and deep learning (free and publicly available) offers a detailed walkthrough with code."}),"\n",(0,t.jsx)(n.li,{children:"Other resources, such as Chris Olah\u2019s blog posts, Distill publications, and various courses, illuminate how modern deep neural networks operate internally."}),"\n"]}),"\n",(0,t.jsxs)(n.h2,{id:"1\ufe0f\u20e3-background-and-motivation",children:["1\ufe0f\u20e3 ",(0,t.jsx)(n.strong,{children:"Background and Motivation"})]}),"\n",(0,t.jsx)(n.p,{children:"Below is a comprehensive, step-by-step explanation of gradient descent and its role in training neural networks, drawing on all the key insights from the video transcript. It covers how a neural network is set up for digit recognition, how the cost function is defined, and how gradient descent iteratively improves the network\u2019s parameters. It also touches on issues like local minima, memorization vs. learning, and how modern networks build upon these ideas."}),"\n",(0,t.jsx)(n.h3,{id:"handwritten-digit-recognition",children:"Handwritten Digit Recognition"}),"\n",(0,t.jsx)(n.p,{children:"A classic benchmark for neural networks is recognizing handwritten digits (0-9) from 28\xd728 grayscale images. Each pixel in this 28\xd728 grid has a value between 0 and 1, and these 784 pixel values form the input to the network. The basic goal is that, given a new digit image, the network outputs the correct label - i.e., the digit it represents."}),"\n",(0,t.jsx)(n.h3,{id:"network-architecture-recap",children:"Network Architecture Recap"}),"\n",(0,t.jsx)(n.p,{children:"A typical neural network for this task has:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["An ",(0,t.jsx)(n.strong,{children:"input layer"})," with 784 neurons (one per pixel)."]}),"\n",(0,t.jsxs)(n.li,{children:["One or more ",(0,t.jsx)(n.strong,{children:"hidden layers"}),", where each neuron computes a weighted sum of the previous layer\u2019s activations plus a bias, and then applies an activation function such as the sigmoid (a \u201csquishing\u201d function) or ReLU (rectified linear unit)."]}),"\n",(0,t.jsxs)(n.li,{children:["An ",(0,t.jsx)(n.strong,{children:"output layer"})," with 10 neurons - one for each possible digit (0 through 9).",(0,t.jsx)(n.br,{}),"\n","The network assigns a \u201cbrightness\u201d or activation level to each of these 10 output neurons, and the digit corresponding to the brightest neuron is considered the predicted class."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"parameters-weights-and-biases",children:"Parameters (Weights and Biases)"}),"\n",(0,t.jsx)(n.p,{children:"Each neuron\u2019s behavior depends on its weights (one weight per connection to the previous layer) and a single bias. With two hidden layers of 16 neurons each, plus the input and output layers, there can be around 13,000 parameters in total. Adjusting these parameters is the crux of how the network \u201clearns\u201d."}),"\n",(0,t.jsxs)(n.h2,{id:"2\ufe0f\u20e3-the-learning-goal-minimizing-cost",children:["2\ufe0f\u20e3 ",(0,t.jsx)(n.strong,{children:"The Learning Goal: Minimizing Cost"})]}),"\n",(0,t.jsx)(n.p,{children:"After randomly initializing all weights and biases, the network initially performs poorly. We need a systematic way to make it better using labeled data - images of digits plus the correct label for each digit."}),"\n",(0,t.jsx)(n.h3,{id:"1-define-a-cost-function",children:"1. Define a Cost Function"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"For each training example, measure the difference between the network\u2019s predicted output and the desired output."}),"\n",(0,t.jsx)(n.li,{children:"A common choice is to sum up the squares of these differences (sometimes called a squared error)."}),"\n",(0,t.jsx)(n.li,{children:"If the network classifies an example correctly and with high confidence, this sum is small. If it\u2019s wildly off, the sum is large."}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"2-average-over-the-entire-training-set",children:"2. Average Over the Entire Training Set"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Because tens of thousands of labeled images are available (the MNIST dataset), we typically look at the ",(0,t.jsx)(n.strong,{children:"average"})," cost across all those samples."]}),"\n",(0,t.jsx)(n.li,{children:"This average cost is a single scalar number that captures how \u201clousy\u201d the current set of weights and biases is."}),"\n",(0,t.jsx)(n.li,{children:"Lowering this average cost means the network is performing better across all examples, not just one."}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"3-local-minima-vs-global-minima",children:"3. Local Minima vs. Global Minima"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"In principle, there could be many ways to adjust the weights such that the network improves. Each \u201cvalley\u201d in the cost-function landscape corresponds to a local minimum."}),"\n",(0,t.jsx)(n.li,{children:"Which local minimum the network ends up in can depend on its initial random parameter settings and the details of the training algorithm."}),"\n"]}),"\n",(0,t.jsxs)(n.h2,{id:"3\ufe0f\u20e3-the-core-algorithm-gradient-descent",children:["3\ufe0f\u20e3 ",(0,t.jsx)(n.strong,{children:"The Core Algorithm: Gradient Descent"})]}),"\n",(0,t.jsx)(n.h3,{id:"key-idea",children:"Key Idea"}),"\n",(0,t.jsx)(n.p,{children:"Gradient descent is the iterative process for finding which direction to shift each weight and bias so that the cost function goes down. Even though the cost function might live in a 13,000-dimensional space, the same intuition from single-variable calculus extends to higher dimensions:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Compute the Gradient"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["The ",(0,t.jsx)(n.strong,{children:"gradient"})," tells you which direction in parameter-space (i.e., which combination of weight/bias adjustments) most rapidly ",(0,t.jsx)(n.strong,{children:"increases"})," the cost."]}),"\n",(0,t.jsxs)(n.li,{children:["Its negative (",(0,t.jsxs)(n.span,{className:"katex",children:[(0,t.jsx)(n.span,{className:"katex-mathml",children:(0,t.jsx)(n.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(n.semantics,{children:[(0,t.jsx)(n.mrow,{children:(0,t.jsx)(n.mo,{children:"\u2212"})}),(0,t.jsx)(n.annotation,{encoding:"application/x-tex",children:"-"})]})})}),(0,t.jsx)(n.span,{className:"katex-html","aria-hidden":"true",children:(0,t.jsxs)(n.span,{className:"base",children:[(0,t.jsx)(n.span,{className:"strut",style:{height:"0.6667em",verticalAlign:"-0.0833em"}}),(0,t.jsx)(n.span,{className:"mord",children:"\u2212"})]})})]}),"gradient) indicates which direction decreases the cost the fastest."]}),"\n",(0,t.jsx)(n.li,{children:"The size (magnitude) of each component in that gradient indicates how important a change in that particular weight/bias is relative to the others."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Take a Small Step Downhill"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Update each weight and bias by a small fraction of its negative gradient component."}),"\n",(0,t.jsx)(n.li,{children:"These small steps ensure you approach a local minimum, and the step size often shrinks as you get closer (like a ball rolling into a valley, slowing down near the bottom)."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Repeat"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"You continually re-compute the new gradient at each step (because once weights change, so do the network outputs and thus the cost landscape)."}),"\n",(0,t.jsx)(n.li,{children:"Keep iterating until changes no longer meaningfully reduce the cost, indicating convergence on a local minimum."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"backpropagation",children:"Backpropagation"}),"\n",(0,t.jsxs)(n.p,{children:["The efficient algorithm used to calculate the gradient in a neural network is known as ",(0,t.jsx)(n.strong,{children:"backpropagation"}),". It systematically applies the chain rule of calculus to propagate errors backward - from the output layer to each hidden layer - assigning credit (or blame) to specific weights. This way, every single weight and bias can be nudged in just the right direction to reduce the overall cost."]}),"\n",(0,t.jsxs)(n.h2,{id:"4\ufe0f\u20e3-performance-and-observations",children:["4\ufe0f\u20e3 ",(0,t.jsx)(n.strong,{children:"Performance and Observations"})]}),"\n",(0,t.jsx)(n.h3,{id:"accuracy-on-new-data",children:"Accuracy on New Data"}),"\n",(0,t.jsx)(n.p,{children:"Once trained, the network is tested on new images it has never seen. A typical two-hidden-layer neural network (with 16 neurons each) can reach about 96% accuracy on the MNIST test set. With a few tweaks (e.g., more layers or different hyperparameters), it can climb to around 98%. While not the absolute state-of-the-art, this still demonstrates that the learned parameters generalize beyond the training data."}),"\n",(0,t.jsx)(n.h3,{id:"hidden-layer-interpretations",children:"Hidden Layer Interpretations"}),"\n",(0,t.jsx)(n.p,{children:"A simple hope was that hidden neurons might each specialize in detecting something like edges or loops. However, in practice, the learned weights for these layers can look random or obscure when visualized. The network still does well at classification; it simply finds its own sometimes-unintuitive way of partitioning the input space."}),"\n",(0,t.jsx)(n.h3,{id:"overconfidence-on-garbage-inputs",children:"Overconfidence on Garbage Inputs"}),"\n",(0,t.jsx)(n.p,{children:"A trained network might respond confidently to random noise, predicting, for instance, a \u201c5\u201d when the input is purely random pixels. This happens because the network only ever sees neat, centered digit images during training. It has no reason (from the cost function\u2019s perspective) to learn caution or produce \u201cuncertain\u201d outputs on unrecognizable inputs."}),"\n",(0,t.jsxs)(n.h2,{id:"5\ufe0f\u20e3-local-minima-and-memorization-in-modern-dl",children:["5\ufe0f\u20e3 ",(0,t.jsx)(n.strong,{children:"Local Minima and \u201cMemorization\u201d in Modern DL"})]}),"\n",(0,t.jsx)(n.h3,{id:"local-minima-as-valleys",children:"Local Minima as Valleys"}),"\n",(0,t.jsx)(n.p,{children:"When gradient descent is applied, it may settle into different local minima depending on how the network is initialized. Deep learning researchers have shown that in high-dimensional parameter spaces, many local minima might have similarly good performance on the training data."}),"\n",(0,t.jsx)(n.h3,{id:"structured-vs-random-labels",children:"Structured vs. Random Labels"}),"\n",(0,t.jsx)(n.p,{children:"A striking experiment involves randomizing the labels of a training set. Remarkably, large networks can memorize these random assignments, achieving near-perfect accuracy on the training data but failing entirely on real images (where the labels are correct). This memorization highlights that neural networks often have enough capacity to overfit without actually learning useful patterns."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Structured Data"}),(0,t.jsx)(n.br,{}),"\n","When the labels do correspond to the right images, the cost function drops much more quickly, indicating the network is learning meaningful patterns rather than merely memorizing."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Memorized Data"}),(0,t.jsx)(n.br,{}),"\n","With randomly shuffled labels, training still converges (the network memorizes the random labels), but the cost decreases more slowly. No actual structure from the images is learned."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"implications",children:"Implications"}),"\n",(0,t.jsxs)(n.p,{children:["These experiments show that although neural networks can overfit to noise, they do tend to find more meaningful parameter configurations ",(0,t.jsx)(n.em,{children:"faster"})," when the dataset is correctly labeled. Modern developments in deep learning build upon such insights, using regularization, data augmentation, or specialized architectures (like convolutional or recurrent networks) to detect more robust patterns and avoid memorizing noise."]}),"\n",(0,t.jsxs)(n.h2,{id:"6\ufe0f\u20e3-beyond-the-basics",children:["6\ufe0f\u20e3 ",(0,t.jsx)(n.strong,{children:"Beyond the Basics"})]}),"\n",(0,t.jsx)(n.h3,{id:"why-continuous-activations",children:"Why Continuous Activations?"}),"\n",(0,t.jsx)(n.p,{children:"To make gradient descent feasible, the network\u2019s activations must be differentiable functions of their inputs. This is why sigmoid-like or ReLU activations are used instead of purely binary on/off switches (as in some simplified biological neuron models). If neuron outputs were discrete, the cost function would not be smooth, and there would be no easy way to compute a gradient."}),"\n",(0,t.jsx)(n.h3,{id:"scaling-up",children:"Scaling Up"}),"\n",(0,t.jsx)(n.p,{children:"The approach to digit classification described here (two hidden layers, fully connected, 16 neurons each) is a small example by modern standards. Current state-of-the-art networks for image tasks often have many layers (dozens or even hundreds) and incorporate convolutional layers, pooling, skip connections, and more. Yet the same core ideas - gradient descent, backpropagation, cost functions - remain the bedrock of training."}),"\n",(0,t.jsxs)(n.h2,{id:"7\ufe0f\u20e3-conclusion",children:["7\ufe0f\u20e3 ",(0,t.jsx)(n.strong,{children:"Conclusion"})]}),"\n",(0,t.jsx)(n.p,{children:"In essence, the story of gradient descent in neural networks is a repeated calculus exercise:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Define a cost function that measures how well (or poorly) the network is classifying the training data."}),"\n",(0,t.jsx)(n.li,{children:"Compute the gradient - a measure of which parameter changes reduce that cost the fastest."}),"\n",(0,t.jsx)(n.li,{children:"Nudge each parameter in the negative gradient\u2019s direction, then repeat."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"This systematic \u201chill descent\u201d drives the network\u2019s weights and biases toward configurations that effectively map handwritten digits to their correct labels. While local minima and memorization raise subtle questions, especially in very large networks, the core principle of gradient descent remains foundational for deep learning. Through careful architectural design and regularization, modern networks learn powerful representations from vast datasets, performing tasks once deemed far beyond the reach of simple layered perceptrons."})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>o});var t=i(96540);const a={},s=t.createContext(a);function r(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);