<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-notes/Information Technology/Artificial Intelligence/👨🏻‍🏫 Google - 02 - ML/google-2-unit-1" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.5.2">
<title data-rh="true">📖 Linear Regression | MindMash</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://github.com/MindMash/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://github.com/MindMash/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://github.com/MindMash/docs/notes/Information Technology/Artificial Intelligence/👨🏻‍🏫 Google - 02 - ML/google-2-unit-1"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="📖 Linear Regression | MindMash"><meta data-rh="true" name="description" content="➡️ Useful Materials"><meta data-rh="true" property="og:description" content="➡️ Useful Materials"><link data-rh="true" rel="icon" href="/MindMash/img/planet-earth.png"><link data-rh="true" rel="canonical" href="https://github.com/MindMash/docs/notes/Information Technology/Artificial Intelligence/👨🏻‍🏫 Google - 02 - ML/google-2-unit-1"><link data-rh="true" rel="alternate" href="https://github.com/MindMash/docs/notes/Information Technology/Artificial Intelligence/👨🏻‍🏫 Google - 02 - ML/google-2-unit-1" hreflang="en"><link data-rh="true" rel="alternate" href="https://github.com/MindMash/docs/notes/Information Technology/Artificial Intelligence/👨🏻‍🏫 Google - 02 - ML/google-2-unit-1" hreflang="x-default"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/MindMash/assets/css/styles.840d84ac.css">
<script src="/MindMash/assets/js/runtime~main.dce65f8d.js" defer="defer"></script>
<script src="/MindMash/assets/js/main.1e46c6d1.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/MindMash/"><div class="navbar__logo"><img src="/MindMash/img/logo.svg" alt="MindMash Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/MindMash/img/logo.svg" alt="MindMash Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">MindMash</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/MindMash/docs/notes/intro">Notes</a><a class="navbar__item navbar__link" href="/MindMash/docs/tracking/intro">Tracking</a><a class="navbar__item navbar__link" href="/MindMash/docs/private/intro-private">Private</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/DanielePassabi" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/MindMash/docs/notes/intro">Introduction to Notes</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/MindMash/docs/notes/Economics and Finance/economia-e-finanza-01">Economics and Finance</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/MindMash/docs/notes/Gym/Consigli Trainer/gym-trainer-insights-03">Gym</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/MindMash/docs/notes/Information Technology/Artificial Intelligence/general-0">Information Technology</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/MindMash/docs/notes/Information Technology/Artificial Intelligence/general-0">Artificial Intelligence</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/MindMash/docs/notes/Information Technology/Artificial Intelligence/general-0">🔡 Glossary</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/MindMash/docs/notes/Information Technology/Artificial Intelligence/LLMs/llms-1">LLMs</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/MindMash/docs/notes/Information Technology/Artificial Intelligence/👨🏻‍🏫 Google - 01 - Intro to ML/google-unit-1">👨🏻‍🏫 Google - 01 - Intro to ML</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/MindMash/docs/notes/Information Technology/Artificial Intelligence/👨🏻‍🏫 Google - 02 - ML/google-2-unit-1">👨🏻‍🏫 Google - 02 - ML</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/MindMash/docs/notes/Information Technology/Artificial Intelligence/👨🏻‍🏫 Google - 02 - ML/google-2-unit-1">📖 Linear Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/MindMash/docs/notes/Information Technology/Artificial Intelligence/👨🏻‍🏫 Google - 02 - ML/google-2-unit-addtional-1">📖 Gradient Descent</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/MindMash/docs/notes/Information Technology/Artificial Intelligence/👨🏻‍🏫 Google - 02 - ML/google-2-unit-2">📖 Logistic Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/MindMash/docs/notes/Information Technology/Artificial Intelligence/👨🏻‍🏫 Google - 02 - ML/google-2-unit-3">📖 Classification</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/MindMash/docs/notes/Information Technology/Artificial Intelligence/👨🏻‍🏫 Google - 02 - ML/google-2-unit-4">📖 Numerical Data</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/MindMash/docs/notes/Information Technology/Artificial Intelligence/👨🏻‍🏫 Google - 02 - ML/google-2-unit-5">📖 Categorical Data</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/MindMash/docs/notes/Information Technology/Artificial Intelligence/👨🏻‍🏫 Google - 02 - ML/google-2-unit-6">📖 Datasets, Generalization, and Overfitting</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/MindMash/docs/notes/Information Technology/Artificial Intelligence/👨🏻‍🏫 HuggingFace - Agents/hf-unit-1">👨🏻‍🏫 HuggingFace - Agents</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/MindMash/docs/notes/Information Technology/Artificial Intelligence/🗃️ Unsorted Notes/ai-01">🗃️ Unsorted Notes</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/MindMash/docs/notes/Information Technology/Python/python-01">Python</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/MindMash/docs/notes/Information Technology/Web Development/wd-intro">Web Development</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/MindMash/docs/notes/Italian Literature/il-intro">Italian Literature</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/MindMash/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Information Technology</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Artificial Intelligence</span><meta itemprop="position" content="2"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">👨🏻‍🏫 Google - 02 - ML</span><meta itemprop="position" content="3"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">📖 Linear Regression</span><meta itemprop="position" content="4"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>📖 Linear Regression</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="️-useful-materials">➡️ <strong>Useful Materials</strong><a href="#️-useful-materials" class="hash-link" aria-label="Direct link to ️-useful-materials" title="Direct link to ️-useful-materials">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="original-source">Original Source<a href="#original-source" class="hash-link" aria-label="Direct link to Original Source" title="Direct link to Original Source">​</a></h3>
<p>You can find here the original course: <a href="https://developers.google.com/machine-learning/crash-course/linear-regression" target="_blank" rel="noopener noreferrer"><strong>Linear Regression</strong></a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1️⃣-introduction">1️⃣ <strong>Introduction</strong><a href="#1️⃣-introduction" class="hash-link" aria-label="Direct link to 1️⃣-introduction" title="Direct link to 1️⃣-introduction">​</a></h2>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Definition</div><div class="admonitionContent_BuS1"><p><strong>Linear regression</strong> is a statistical technique used to find the relationship between variables. In an ML context, linear regression finds the relationship between <strong>features</strong> and a <strong>label</strong>.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2️⃣-example-fuel-efficiency">2️⃣ <strong>Example: Fuel Efficiency</strong><a href="#2️⃣-example-fuel-efficiency" class="hash-link" aria-label="Direct link to 2️⃣-example-fuel-efficiency" title="Direct link to 2️⃣-example-fuel-efficiency">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="single-feature">Single Feature<a href="#single-feature" class="hash-link" aria-label="Direct link to Single Feature" title="Direct link to Single Feature">​</a></h3>
<p>Linear regression is one of the most straightforward techniques for modeling how an input variable (or set of input variables) relates to an output variable. In this example, we aim to predict a <strong>car’s fuel efficiency</strong>, measured in <strong>miles per gallon</strong> (mpg), based on its <strong>weight</strong> in pounds. Intuitively, heavier cars tend to have lower mpg; the data we observe should help us quantify that relationship and make predictions for new cars.</p>
<p>In our small dataset, we record the weight in thousands of pounds along with the corresponding fuel efficiency in mpg. When plotted, the data points form a downward-sloping trend, confirming the intuitive idea that as weight increases, mpg decreases.</p>
<p><img decoding="async" loading="lazy" alt="My Image" src="/MindMash/assets/images/car-data-points-b758be1cd7d41e3992a1885d60b2a08b.png" width="5274" height="1930" class="img_ev3q"></p>
<p>Next, we introduce a line that best fits these points. By “best fit,” we mean that the line is drawn in such a way as to minimize the overall distance between each point and the line itself, reflecting the best average relationship between weight and mpg.</p>
<p><img decoding="async" loading="lazy" alt="My Image" src="/MindMash/assets/images/car-data-points-with-model-b6127ef82d7faa5a1623892df9d35b8c.png" width="5274" height="2033" class="img_ev3q"></p>
<p>Mathematically, we often express a simple linear regression model using the familiar equation of a line:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>y</mi><mo>=</mo><mi>m</mi><mi>x</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">y = mx + b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em"></span><span class="mord mathnormal">m</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">b</span></span></span></span></span>
<p>where:</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span></span></span> is the value we want to predict</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">m</span></span></span></span> is the slope</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">x</span></span></span></span> is our input variable</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">b</span></span></span></span> is the intercept on the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span></span></span>-axis.</li>
</ul>
<p>In machine learning (ML) terminology, we reframe this equation slightly as:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>y</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><mi>b</mi><mo>+</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">y&#x27; = b + w_1 x_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9963em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>
<p>where:</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">y&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9463em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> is the predicted label (the output)</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">b</span></span></span></span> (or <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">w_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>) is called the bias (analogous to the intercept)</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">w_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> is the weight of our feature (analogous to the slope <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">m</span></span></span></span>)</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">x_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> is the input feature itself.</li>
</ul>
<p>Both <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">b</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">w_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> are parameters <strong>learned from data during the training phase</strong>.</p>
<p>Each part of the equation corresponds to a different concept in the model: the bias shifts the line up or down, while the weight determines the steepness of the line and whether it slopes upward or downward. In this car example, once the best fitting line is found, the learned parameters turn out to be a bias of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>30</mn></mrow><annotation encoding="application/x-tex">30</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">30</span></span></span></span> and a weight of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>3.6</mn></mrow><annotation encoding="application/x-tex">-3.6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">3.6</span></span></span></span>. Thus, we can write the model as:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>y</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><mn>30</mn><mo>+</mo><mo stretchy="false">(</mo><mo>−</mo><mn>3.6</mn><mo stretchy="false">)</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">y&#x27; = 30 + (-3.6)(x_1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9963em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">30</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">3.6</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>
<p>Here, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">y&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9463em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> is our predicted mpg, and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">x_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> is the weight of the car in thousands of pounds. Interpreting these values, the slope of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>3.6</mn></mrow><annotation encoding="application/x-tex">-3.6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">3.6</span></span></span></span> indicates that for every additional thousand pounds in weight, the mpg drops by 3.6, while the model starts at 30 mpg for a hypothetical car with zero weight (which is just a mathematical convenience).</p>
<p>To make a prediction for a new car, simply plug the car’s weight into the model. For example, if a car weighs 4,000 pounds (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>=</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">x_1 = 4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">4</span></span></span></span> in thousands of pounds), its predicted miles per gallon is</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>y</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><mn>30</mn><mo>+</mo><mo stretchy="false">(</mo><mo>−</mo><mn>3.6</mn><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mn>4</mn><mo stretchy="false">)</mo><mo>=</mo><mn>30</mn><mo>−</mo><mn>14.4</mn><mo>=</mo><mn>15.6</mn></mrow><annotation encoding="application/x-tex">y&#x27; = 30 + (-3.6)(4) = 30 - 14.4 = 15.6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9963em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">30</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">3.6</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord">4</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">30</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">14.4</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">15.6</span></span></span></span></span>
<p><img decoding="async" loading="lazy" alt="My Image" src="/MindMash/assets/images/model-prediction-07e55ddfafd65bb0fe1d94bb414101a4.png" width="5274" height="2014" class="img_ev3q"></p>
<p>This predicted mpg aligns with the general downward trend we see in the data. By establishing this linear model, we have a concise way to estimate fuel efficiency for cars of various weights. While this example uses just one feature (car weight), linear regression can incorporate many features, each with its own weight, and remains a foundational technique in machine learning for analyzing relationships between inputs and outputs.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="multiple-features">Multiple Features<a href="#multiple-features" class="hash-link" aria-label="Direct link to Multiple Features" title="Direct link to Multiple Features">​</a></h3>
<p>Linear regression can naturally extend beyond a single feature to incorporate multiple features. This becomes useful when you want to capture <strong>more complex behavior</strong> than a single input can explain.</p>
<p>For instance, in the simple example above, <em>weight</em> alone serves as a predictor of miles per gallon. However, in reality, a car’s mileage often depends on other factors such as <em>engine displacement</em>, <em>acceleration</em>, <em>number of cylinders</em> and <em>horsepower</em>.</p>
<p>A model using five features is typically written as:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>y</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><mi>b</mi><mo>+</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><msub><mi>w</mi><mn>3</mn></msub><msub><mi>x</mi><mn>3</mn></msub><mo>+</mo><msub><mi>w</mi><mn>4</mn></msub><msub><mi>x</mi><mn>4</mn></msub><mo>+</mo><msub><mi>w</mi><mn>5</mn></msub><msub><mi>x</mi><mn>5</mn></msub></mrow><annotation encoding="application/x-tex">y&#x27; = b + w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4 + w_5 x_5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9963em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>
<p>This means we have five input features - <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">x_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> through <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>5</mn></msub></mrow><annotation encoding="application/x-tex">x_5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> - each multiplied by its own learned weight <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">w_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>. The bias <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">b</span></span></span></span> still shifts the entire plane (or hyperplane, when there are more than two features) up or down.</p>
<p><img decoding="async" loading="lazy" alt="My Image" src="/MindMash/assets/images/equation-multiple-features-0f5258b0c7dbe91b6943490f23a0edc0.png" width="1600" height="337" class="img_ev3q"></p>
<p>By plotting these features against miles per gallon, clear patterns emerge:</p>
<ul>
<li>As displacement increases, mileage tends to drop.</li>
<li>Similarly, when a car accelerates more slowly (taking a longer time to reach sixty mph), it often has higher mpg, indicating a positive relationship.</li>
<li>Meanwhile, horsepower shows the opposite trend, where more powerful engines generally achieve lower mpg, mirroring the negative relationship we saw with weight and displacement.</li>
</ul>
<p><img decoding="async" loading="lazy" alt="My Image" src="/MindMash/assets/images/relations-ab5bebe6408aeb0c2f214f65c067d3f9.png" width="2240" height="322" class="img_ev3q"></p>
<p>In practice, fitting a multi-feature linear model involves finding the best values of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">b</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo></mrow><annotation encoding="application/x-tex">w_1, w_2, \dots</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner">…</span></span></span></span> such that the predictions <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">y&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9463em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7519em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span> align as closely as possible with the actual mpg values in the training data. The model then generalizes to new cars by plugging in the appropriate values for each feature, thereby leveraging a richer set of inputs for more accurate predictions.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3️⃣-loss">3️⃣ <strong>Loss</strong><a href="#3️⃣-loss" class="hash-link" aria-label="Direct link to 3️⃣-loss" title="Direct link to 3️⃣-loss">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction">​</a></h3>
<p>Loss is a numerical metric that represents <strong>how far off a model’s predictions are from the true labels</strong>, providing a single value that quantifies the model’s overall error. During training, the goal is to <strong>minimize this loss</strong>, pushing the predictions ever closer to the actual values.</p>
<p><img decoding="async" loading="lazy" alt="My Image" src="/MindMash/assets/images/loss-lines-6378ecb6a94c02729a5080977fb7a746.png" width="5274" height="2520" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="distance-of-loss">Distance of loss<a href="#distance-of-loss" class="hash-link" aria-label="Direct link to Distance of loss" title="Direct link to Distance of loss">​</a></h3>
<p>In the following image, arrows show the distance between each data point and the model’s prediction; loss captures the magnitude of the error rather than its direction. For example, if a model predicts <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">2</span></span></span></span> when the correct value is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn></mrow><annotation encoding="application/x-tex">5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">5</span></span></span></span>, the error might be <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">-3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">3</span></span></span></span> algebraically, but loss treats this simply as a distance of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3</span></span></span></span>. Consequently, common techniques such as taking the absolute value or squaring the difference ensure the sign of the error is removed, focusing attention purely on <strong>how large the mismatch is</strong>. By reducing this mismatch systematically, the model improves its predictive power.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="types-of-loss">Types of loss<a href="#types-of-loss" class="hash-link" aria-label="Direct link to Types of loss" title="Direct link to Types of loss">​</a></h3>
<p>In linear regression, several different loss functions can be employed, each reflecting a slightly different perspective on errors. As the following table shows, the fundamental distinction among these common loss types is how they measure the distance between predictions and actual values.</p>
<ul>
<li>
<p><strong>L1-based metrics</strong> (the sum or average of absolute differences)<br>
<!-- -->Treat errors of any magnitude equally.</p>
</li>
<li>
<p><strong>L2-based metrics</strong> (the sum or average of squared differences)<br>
<!-- -->Emphasize larger errors more heavily. Specifically, squaring magnifies the effect of an error when the difference is big, but downplays it for small differences.</p>
</li>
</ul>
<p>To handle multiple examples at once, it is common to compute the <strong>average loss</strong> - whether via MAE or MSE - so that all examples contribute proportionally to training.</p>
<table><thead><tr><th><strong>Loss type</strong></th><th><strong>Definition</strong></th><th><strong>Equation</strong></th></tr></thead><tbody><tr><td><em>L1 loss</em></td><td>Sum of the absolute values of the differences.</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∑</mo><mo stretchy="false">∣</mo><mtext>actual value</mtext><mo>−</mo><mtext>predicted value</mtext><mo stretchy="false">∣</mo></mrow><annotation encoding="application/x-tex">\sum \lvert \text{actual value} - \text{predicted value} \rvert</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="mopen">∣</span><span class="mord text"><span class="mord">actual value</span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">predicted value</span></span><span class="mclose">∣</span></span></span></span></td></tr><tr><td><em>Mean absolute error (MAE)</em></td><td>Average of the L1 losses across a set of examples.</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mi>N</mi></mfrac><mo>∑</mo><mo stretchy="false">∣</mo><mtext>actual value</mtext><mo>−</mo><mtext>predicted value</mtext><mo stretchy="false">∣</mo></mrow><annotation encoding="application/x-tex">\frac{1}{N} \sum \lvert \text{actual value} - \text{predicted value} \rvert</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="mopen">∣</span><span class="mord text"><span class="mord">actual value</span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">predicted value</span></span><span class="mclose">∣</span></span></span></span></td></tr><tr><td><em>L2 loss</em></td><td>Sum of the squared differences.</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∑</mo><mo stretchy="false">(</mo><mtext>actual value</mtext><mo>−</mo><mtext>predicted value</mtext><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\sum (\text{actual value} - \text{predicted value})^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="mopen">(</span><span class="mord text"><span class="mord">actual value</span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">predicted value</span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></td></tr><tr><td><em>Mean squared error (MSE)</em></td><td>Average of the L2 losses across a set of examples.</td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mi>N</mi></mfrac><mo>∑</mo><mo stretchy="false">(</mo><mtext>actual value</mtext><mo>−</mo><mtext>predicted value</mtext><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\frac{1}{N} \sum (\text{actual value} - \text{predicted value})^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="mopen">(</span><span class="mord text"><span class="mord">actual value</span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">predicted value</span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></td></tr></tbody></table>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Example: Calculating Loss</div><div class="admonitionContent_BuS1"><p>Suppose we use the earlier best fit line, where the weight (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">w_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>) is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>3.6</mn></mrow><annotation encoding="application/x-tex">-3.6</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">3.6</span></span></span></span> and the bias (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">b</span></span></span></span>) is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>30</mn></mrow><annotation encoding="application/x-tex">30</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">30</span></span></span></span>. If we plug in a weight of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2.37</mn></mrow><annotation encoding="application/x-tex">2.37</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">2.37</span></span></span></span> (2,370 pounds, since our graphs are scaled to thousands of pounds), the model predicts:</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>prediction</mtext><mo>=</mo><mi>b</mi><mo>+</mo><mo stretchy="false">(</mo><msub><mi>w</mi><mn>1</mn></msub><mo>×</mo><mn>2.37</mn><mo stretchy="false">)</mo><mo>=</mo><mn>30</mn><mo>+</mo><mo stretchy="false">(</mo><mo>−</mo><mn>3.6</mn><mo>×</mo><mn>2.37</mn><mo stretchy="false">)</mo><mo>=</mo><mn>21.5.</mn></mrow><annotation encoding="application/x-tex">\text{prediction} = b + (w_1 \times 2.37) = 30 + (-3.6 \times 2.37) = 21.5.</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord text"><span class="mord">prediction</span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal">b</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">2.37</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">30</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">3.6</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">2.37</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">21.5.</span></span></span></span></span><p>However, suppose the true mpg for this car is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>24</mn></mrow><annotation encoding="application/x-tex">24</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">24</span></span></span></span>. The L2 loss (the squared difference) between the model’s prediction and the actual value is:</p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><mtext>actual value</mtext><mo>−</mo><mtext>predicted value</mtext><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>=</mo><mo stretchy="false">(</mo><mn>24</mn><mo>−</mo><mn>21.5</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>=</mo><mn>6.25.</mn></mrow><annotation encoding="application/x-tex">(\text{actual value} - \text{predicted value})^2 = (24 - 21.5)^2 = 6.25.</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord text"><span class="mord">actual value</span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">predicted value</span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">24</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em"></span><span class="mord">21.5</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">6.25.</span></span></span></span></span><p>In other words, for this single data point, the L2 loss is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6.25</mn></mrow><annotation encoding="application/x-tex">6.25</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">6.25</span></span></span></span>. This number represents the degree to which the model’s prediction deviates from reality, an error the model will try to minimize during training.</p></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="choosing-a-loss">Choosing a loss<a href="#choosing-a-loss" class="hash-link" aria-label="Direct link to Choosing a loss" title="Direct link to Choosing a loss">​</a></h3>
<p>When deciding whether to use MAE or MSE, you should consider <strong>how your dataset handles outliers</strong> and how you want the model to treat them. While most car weights fall within 2,000 to 5,000 pounds and typical fuel efficiencies range from 8 to 50 miles per gallon, an 8,000-pound car or a 100-mpg vehicle would be well outside the norm. This kind of outlier can also refer to how far off a model’s prediction is from its actual value. For example, a 3,000-pound car that actually achieves 40 miles per gallon might seem realistic in isolation, but it would be an outlier if the model only predicts 18 to 20 miles per gallon for such a car.</p>
<p>If your model uses MSE, outliers incur a <strong>very large penalty</strong> because the difference between predicted and actual values is squared. Therefore, the model will adjust its parameters more aggressively to reduce errors at these unusual points, sometimes at the expense of slightly worse predictions for the rest of the dataset. By contrast, MAE is <strong>less influenced by outliers</strong> because it takes the absolute value rather than the square. Consequently, MAE tends to keep the model closer to most data points overall, sometimes allowing larger deviations on a few outliers.</p>
<p>Graphically, MSE-trained models often appear closer to outliers, while MAE-trained models stay closer to the bulk of the data. The choice ultimately depends on whether you want the model to emphasize accuracy for outliers or to focus on minimizing errors for typical cases.</p>
<p><img decoding="async" loading="lazy" alt="My Image" src="/MindMash/assets/images/model-mse-95e6512387099116d62fec2457156e07.png" width="1600" height="711" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" alt="My Image" src="/MindMash/assets/images/model-mae-fea0b9a37968bb7501ca704b9fd41c51.png" width="1600" height="711" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4️⃣-gradient-descent">4️⃣ <strong>Gradient Descent</strong><a href="#4️⃣-gradient-descent" class="hash-link" aria-label="Direct link to 4️⃣-gradient-descent" title="Direct link to 4️⃣-gradient-descent">​</a></h2>
<p>Gradient descent is an <strong>iterative algorithm</strong> that systematically searches for the <strong>weight</strong> and <strong>bias</strong> values producing the lowest possible loss.</p>
<iframe src="https://www.youtube.com/embed/QoK1nNAURw4" title="Machine Learning Crash Course: Gradient Descent" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" class="video-holidays"></iframe>
<p>It begins by assigning random values close to zero for these parameters. Then, at every iteration, it calculates the current loss, determines which direction to adjust the parameters to reduce that loss, and shifts the weight and bias slightly in that direction.</p>
<p>This process repeats until further adjustments do not meaningfully lower the loss. Conceptually, each iteration nudges the parameters down the “slope” of a loss landscape, moving step by step toward the minimum.</p>
<p>As illustrated by the following diagram, gradient descent fine-tunes the model’s parameters until it finds the point of least error, thereby yielding the best-fitting line for your dataset.</p>
<p><img decoding="async" loading="lazy" alt="My Image" src="/MindMash/assets/images/gradient-descent-ed36b64e5aa698f0fdf83888039e032f.png" width="1116" height="841" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="5️⃣-model-convergence-and-loss-curves">5️⃣ <strong>Model convergence and loss curves</strong><a href="#5️⃣-model-convergence-and-loss-curves" class="hash-link" aria-label="Direct link to 5️⃣-model-convergence-and-loss-curves" title="Direct link to 5️⃣-model-convergence-and-loss-curves">​</a></h2>
<p>When training a model - <em>particularly with gradient-based methods</em> - one of the most common diagnostic tools is the <strong>loss curve</strong>. This curve shows how the model’s loss changes over time or across iterations (or epochs) of training. A typical loss curve will steeply decrease early in training, then gradually level out as the model converges.</p>
<p><img decoding="async" loading="lazy" alt="My Image" src="/MindMash/assets/images/convergence-bd4aafb9cdcae7b56292a4d20467f9db.png" width="586" height="463" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="interpreting-the-loss-curve">Interpreting the Loss Curve<a href="#interpreting-the-loss-curve" class="hash-link" aria-label="Direct link to Interpreting the Loss Curve" title="Direct link to Interpreting the Loss Curve">​</a></h3>
<ul>
<li>
<p><strong>Rapid Initial Decrease</strong><br>
<!-- -->In the early iterations, large updates to the parameters (weights and bias) typically occur, causing a swift drop in loss. This reflects the model quickly learning rudimentary patterns in the data.</p>
</li>
<li>
<p><strong>Gradual Convergence</strong><br>
<!-- -->As training continues, the slope of the curve flattens because updates become smaller; the model refines its understanding of the data, making ever-finer adjustments. The loss curve often plateaus when the parameters reach a state where further improvements are minimal - this is commonly referred to as <strong>convergence</strong>.</p>
</li>
<li>
<p><strong>Identifying the Convergence Point</strong><br>
<!-- -->The iteration at which the loss curve levels off (for example, around the 1,000th iteration) typically indicates that the model has converged. At this point, additional iterations may not yield substantial improvements in the training loss.</p>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="snapshots-of-model-training">Snapshots of Model Training<a href="#snapshots-of-model-training" class="hash-link" aria-label="Direct link to Snapshots of Model Training" title="Direct link to Snapshots of Model Training">​</a></h3>
<p>Visualizing snapshots of the model (for instance, in a regression problem) at different points in training makes it clear how updates to weights and bias correspond to decreasing loss.</p>
<ol>
<li><strong>Early Iterations (e.g., 2nd iteration)</strong>
<ul>
<li>The model parameters are often close to their initial random values, so predictions are poor.</li>
<li>The <em>loss lines</em> in a plot (lines showing the difference between predicted and actual points) are typically long, indicating large errors.</li>
</ul>
</li>
</ol>
<p><img decoding="async" loading="lazy" alt="My Image" src="/MindMash/assets/images/large-loss-280d3cf457d9ca071745a9f620f7b36d.png" width="4815" height="1629" class="img_ev3q"></p>
<ol start="2">
<li><strong>Midway Through Training (e.g., 400th iteration)</strong>
<ul>
<li>The model has significantly improved; weights and bias are starting to align with the true underlying relationship in the data.</li>
<li>Loss is lower than in the early stage, but there might still be noticeable prediction errors.</li>
</ul>
</li>
</ol>
<p><img decoding="async" loading="lazy" alt="My Image" src="/MindMash/assets/images/med-loss-5de599a1b235f35b36066b6a23e9c0bb.png" width="1000" height="339" class="img_ev3q"></p>
<ol start="3">
<li><strong>Late Iterations (e.g., 1,000th iteration)</strong>
<ul>
<li>The model parameters have <em>converged</em>, or nearly so, to the optimal values for minimizing loss.</li>
<li>Prediction errors are minimal, and loss lines are much shorter in visualizations.</li>
</ul>
</li>
</ol>
<p><img decoding="async" loading="lazy" alt="My Image" src="/MindMash/assets/images/low-loss-6caac4909013b3cd4fc6e6e56f87f510.png" width="2000" height="677" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="factors-affecting-convergence">Factors Affecting Convergence<a href="#factors-affecting-convergence" class="hash-link" aria-label="Direct link to Factors Affecting Convergence" title="Direct link to Factors Affecting Convergence">​</a></h3>
<ul>
<li>
<p><strong>Learning Rate</strong><br>
<!-- -->A learning rate that is too large can cause the loss to oscillate or even diverge, while a learning rate that is too small can slow down training significantly or get stuck in suboptimal minima.</p>
</li>
<li>
<p><strong>Overfitting / Underfitting</strong><br>
<!-- -->While the model may appear to converge on the training set, it’s also important to check validation and test losses to ensure the model is not <em>overfitting</em>.<br>
<!-- -->If both training and validation losses stop improving, that often indicates genuine convergence.</p>
</li>
<li>
<p><strong>Data Quality and Complexity</strong><br>
<!-- -->Poorly scaled or noisy data can adversely affect the loss curve and delay or prevent proper convergence.<br>
<!-- -->The complexity of the chosen model (e.g., neural network depth, number of parameters in linear regression) can also shape the nature of convergence.</p>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="convergence-and-convex-functions">Convergence and convex functions<a href="#convergence-and-convex-functions" class="hash-link" aria-label="Direct link to Convergence and convex functions" title="Direct link to Convergence and convex functions">​</a></h3>
<p>The loss functions for linear models always produce a <strong>convex</strong> surface.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Convex Function</div><div class="admonitionContent_BuS1"><p>A function in which the region above the graph of the function is a <strong>convex set</strong>.</p><p>For example, the following are all convex functions:</p><p><img decoding="async" loading="lazy" alt="My Image" src="/MindMash/assets/images/convex_functions-de66130eef3f499a72ac0531d958489b.png" width="1128" height="288" class="img_ev3q"></p><p>In contrast, the following function is not convex.</p><p><img decoding="async" loading="lazy" alt="My Image" src="/MindMash/assets/images/nonconvex_function-c4c6da7ba090af96fe8aa69377570174.svg" width="379" height="299" class="img_ev3q"></p></div></div>
<p>This convexity ensures that when a linear regression model converges, it has found the <strong>optimal</strong> weights and bias that minimize the loss.</p>
<p>If we visualize the loss surface for a model with a single feature, we can observe its characteristic convex shape. In the following example, a weight of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>5.44</mn></mrow><annotation encoding="application/x-tex">-5.44</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">5.44</span></span></span></span> and bias of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>35.94</mn></mrow><annotation encoding="application/x-tex">35.94</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">35.94</span></span></span></span> produce the lowest loss at <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5.54</mn></mrow><annotation encoding="application/x-tex">5.54</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">5.54</span></span></span></span>.</p>
<p><img decoding="async" loading="lazy" alt="My Image" src="/MindMash/assets/images/convexity-deadb560858d98c292d56f3e739d28db.png" width="4807" height="1985" class="img_ev3q"></p>
<p>It&#x27;s important to note that the model almost never finds the exact minimum for each weight and bias, but instead finds a value very close to it. It&#x27;s also important to note that the minimum for the weights and bias don&#x27;t correspond to zero loss, only a value that produces the lowest loss for that parameter.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="6️⃣-hyperparameters">6️⃣ <strong>Hyperparameters</strong><a href="#6️⃣-hyperparameters" class="hash-link" aria-label="Direct link to 6️⃣-hyperparameters" title="Direct link to 6️⃣-hyperparameters">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="introduction-1">Introduction<a href="#introduction-1" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction">​</a></h3>
<p>In machine learning, particularly during the training phase, hyperparameters play a critical role in influencing model performance. <strong>Hyperparameters</strong> are variables that the practitioner sets before the training process begins. Unlike model parameters, which the model learns from data during training (such as weights and biases), hyperparameters must be configured manually or through an automated tuning process.</p>
<p>Understanding and effectively choosing hyperparameters is essential for building efficient, accurate machine learning models. This report provides a detailed exploration of hyperparameters, emphasizing three common hyperparameters: <strong>Learning Rate</strong>, <strong>Batch Size</strong>, and <strong>Epochs</strong>.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="parameters-vs-hyperparameters">Parameters vs. Hyperparameters<a href="#parameters-vs-hyperparameters" class="hash-link" aria-label="Direct link to Parameters vs. Hyperparameters" title="Direct link to Parameters vs. Hyperparameters">​</a></h3>
<p>To clearly understand hyperparameters, it&#x27;s crucial to distinguish them from <strong>parameters</strong>:</p>
<ul>
<li>
<p><strong>Parameters</strong><br>
<!-- -->These are the internal values the model updates during training, such as weights and biases. They are learned directly from the data by minimizing the loss function.</p>
</li>
<li>
<p><strong>Hyperparameters</strong><br>
<!-- -->These are external configurations set by the developer before training begins. They control various aspects of the training process but are not updated directly by training algorithms.</p>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="learning-rate">Learning Rate<a href="#learning-rate" class="hash-link" aria-label="Direct link to Learning Rate" title="Direct link to Learning Rate">​</a></h3>
<p>The <strong>learning rate</strong> is a crucial hyperparameter that controls how rapidly a machine learning model learns by determining the magnitude of the updates to its internal parameters.</p>
<p>The learning rate is typically a <strong>small positive floating-point number</strong> (e.g., <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.01</mn></mrow><annotation encoding="application/x-tex">0.01</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.01</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.001</mn></mrow><annotation encoding="application/x-tex">0.001</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.001</span></span></span></span>). It controls how drastically the model adjusts its weights and biases in response to the calculated gradients during training.</p>
<ul>
<li>
<p><strong>High Learning Rate</strong><br>
<!-- -->Leads to rapid updates and quicker training initially. However, excessively large learning rates can cause instability, preventing convergence and causing the model&#x27;s parameters to oscillate or diverge.</p>
</li>
<li>
<p><strong>Low Learning Rate</strong><br>
<!-- -->Leads to slower updates and stable convergence but increases training duration and may risk becoming stuck in local minima.</p>
</li>
</ul>
<p><img decoding="async" loading="lazy" alt="My Image" src="/MindMash/assets/images/lr-81943d11292b35aaff8411a0d3277ef2.png" width="1355" height="1171" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="-role-in-gradient-descent">➽ Role in Gradient Descent<a href="#-role-in-gradient-descent" class="hash-link" aria-label="Direct link to ➽ Role in Gradient Descent" title="Direct link to ➽ Role in Gradient Descent">​</a></h4>
<p>In the gradient descent optimization process, the learning rate determines how large a step the model takes in the direction of steepest descent on the loss function:</p>
<ul>
<li>After computing gradients (the slope of the loss function concerning each parameter), these gradients are multiplied by the learning rate to update the parameters:</li>
</ul>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>new_parameter</mtext><mo>=</mo><mtext>old_parameter</mtext><mo>−</mo><mo stretchy="false">(</mo><mtext>learning_rate</mtext><mo>×</mo><mtext>gradient</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{new\_parameter} = \text{old\_parameter} - (\text{learning\_rate} \times \text{gradient})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9251em;vertical-align:-0.31em"></span><span class="mord text"><span class="mord">new_parameter</span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em"></span><span class="mord text"><span class="mord">old_parameter</span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em"></span><span class="mopen">(</span><span class="mord text"><span class="mord">learning_rate</span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">gradient</span></span><span class="mclose">)</span></span></span></span></span>
<ul>
<li>For example, if the gradient magnitude is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2.5</mn></mrow><annotation encoding="application/x-tex">2.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">2.5</span></span></span></span> and the learning rate is <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.01</mn></mrow><annotation encoding="application/x-tex">0.01</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.01</span></span></span></span>, the parameter will change by:</li>
</ul>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mn>2.5</mn><mo>×</mo><mn>0.01</mn><mo>=</mo><mn>0.025</mn></mrow><annotation encoding="application/x-tex">2.5 \times 0.01 = 0.025</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">2.5</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.01</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.025</span></span></span></span></span>
<p>Thus, the adjustment made at each iteration is proportional both to the learning rate and the gradient magnitude.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="-practical-considerations">➽ Practical Considerations<a href="#-practical-considerations" class="hash-link" aria-label="Direct link to ➽ Practical Considerations" title="Direct link to ➽ Practical Considerations">​</a></h4>
<p>Selecting the optimal learning rate often involves experimentation and careful tuning. Common approaches include:</p>
<ul>
<li>
<p><strong>Learning Rate Schedules</strong><br>
<!-- -->Techniques such as exponential decay or cyclic learning rates dynamically adjust the learning rate throughout training.</p>
</li>
<li>
<p><strong>Adaptive Optimizers</strong><br>
<!-- -->Algorithms like Adam, RMSProp, or Adagrad automatically adjust the learning rate during training to accelerate convergence and improve stability.</p>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="batch-size">Batch Size<a href="#batch-size" class="hash-link" aria-label="Direct link to Batch Size" title="Direct link to Batch Size">​</a></h3>
<p><strong>Batch size</strong> is a hyperparameter referring to the number of training examples a model processes before updating its weights and biases. It significantly impacts the efficiency and convergence characteristics of the training process.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="-definition-and-significance">➽ Definition and Significance<a href="#-definition-and-significance" class="hash-link" aria-label="Direct link to ➽ Definition and Significance" title="Direct link to ➽ Definition and Significance">​</a></h4>
<p>When training machine learning models, you might initially think it&#x27;s ideal to compute the loss using all examples in the dataset simultaneously (known as <strong>full-batch gradient descent</strong>) before updating parameters. However, in practical scenarios involving datasets with hundreds of thousands or even millions of examples, this approach becomes computationally infeasible due to memory and processing constraints.</p>
<p>Consequently, alternative strategies are employed, particularly:</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="-stochastic-gradient-descent-sgd">➽ Stochastic Gradient Descent (SGD)<a href="#-stochastic-gradient-descent-sgd" class="hash-link" aria-label="Direct link to ➽ Stochastic Gradient Descent (SGD)" title="Direct link to ➽ Stochastic Gradient Descent (SGD)">​</a></h4>
<p>Stochastic gradient descent involves using a <strong>batch size of one</strong>. In other words, the model updates its parameters after evaluating just a single randomly chosen training example in each iteration.</p>
<ul>
<li><strong>Pros</strong>
<ul>
<li>Rapid parameter updates.</li>
<li>Can avoid local minima due to inherent randomness.</li>
</ul>
</li>
<li><strong>Cons</strong>
<ul>
<li>High variance and noise, leading to fluctuations in the loss.</li>
<li>Less stable convergence, potentially requiring more iterations.</li>
</ul>
</li>
</ul>
<p>Noise here refers to random fluctuations during training, which can temporarily increase the loss instead of consistently decreasing it. While this can seem undesirable, controlled noise can help models escape local minima, leading to better generalization.</p>
<p><strong>Illustrative Example</strong><br>
<!-- -->A loss curve resulting from training with SGD typically demonstrates significant fluctuations throughout training. Although the loss generally decreases over time, these fluctuations persist even near convergence.</p>
<p><img decoding="async" loading="lazy" alt="My Image" src="/MindMash/assets/images/noisy-gradient-6f6e6167ea3f88ca7ae85834e7e04f66.png" width="612" height="478" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="-mini-batch-stochastic-gradient-descent-mini-batch-sgd">➽ Mini-batch Stochastic Gradient Descent (Mini-batch SGD)<a href="#-mini-batch-stochastic-gradient-descent-mini-batch-sgd" class="hash-link" aria-label="Direct link to ➽ Mini-batch Stochastic Gradient Descent (Mini-batch SGD)" title="Direct link to ➽ Mini-batch Stochastic Gradient Descent (Mini-batch SGD)">​</a></h4>
<p>Mini-batch stochastic gradient descent represents a <em>compromise</em> between the two extremes of full-batch gradient descent and stochastic gradient descent. Rather than updating parameters after processing every single example or the entire dataset at once, mini-batch SGD updates parameters after processing a <strong>subset of training examples</strong>, typically ranging from dozens to several hundreds or even thousands.</p>
<ul>
<li><strong>Pros</strong>
<ul>
<li>Balances the efficiency of batch processing with the variability and generalization advantages of stochastic methods.</li>
<li>Reduced noise compared to SGD.</li>
<li>Better hardware utilization and computational efficiency.</li>
</ul>
</li>
<li><strong>Cons</strong>
<ul>
<li>Requires tuning batch size to balance convergence stability and computational resources.</li>
</ul>
</li>
</ul>
<p>The examples included in each mini-batch are selected randomly, and their gradients are averaged. This average gradient is then used for a single parameter update per iteration.</p>
<p><strong>Illustrative Example</strong><br>
<!-- -->A loss curve trained with mini-batch SGD typically shows a smoother decrease than SGD, with fewer and smaller fluctuations, especially near convergence.</p>
<p><img decoding="async" loading="lazy" alt="My Image" src="/MindMash/assets/images/mini-batch-sgd-01e9c3120688744bd04d880bcf4ecbdb.png" width="628" height="481" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="-determining-optimal-batch-size">➽ Determining Optimal Batch Size<a href="#-determining-optimal-batch-size" class="hash-link" aria-label="Direct link to ➽ Determining Optimal Batch Size" title="Direct link to ➽ Determining Optimal Batch Size">​</a></h4>
<p>The optimal batch size depends on multiple factors, such as dataset size, model complexity, and computational resources (e.g., available GPU memory). Generally:</p>
<ul>
<li><strong>Smaller batch sizes</strong><br>
<!-- -->Behave similarly to SGD, with higher noise and potentially improved generalization.</li>
<li><strong>Larger batch sizes</strong><br>
<!-- -->Approach full-batch behavior, offering smoother but potentially slower convergence and possibly worse generalization.</li>
</ul>
<p>Selecting the batch size thus becomes a trade-off between stability, speed of convergence, computational resources, and the generalization performance of the trained model.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="-role-of-noise">➽ Role of Noise<a href="#-role-of-noise" class="hash-link" aria-label="Direct link to ➽ Role of Noise" title="Direct link to ➽ Role of Noise">​</a></h4>
<p>Although noise might initially appear detrimental because it causes variability in the loss curve, controlled levels of noise introduced by smaller batch sizes can positively influence training:</p>
<ul>
<li>Noise can help the model avoid getting trapped in local minima, potentially leading to better generalization.</li>
<li>Controlled noise can enable the model to explore the loss landscape more effectively, resulting in more robust and generalized parameter values.</li>
</ul>
<p>As a result, a moderate level of noise - carefully balanced through the batch size - is desirable rather than something to eliminate entirely.</p>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>Why Smaller Batch Sizes improve Generalization?</div><div class="admonitionContent_BuS1"><p>The relationship between smaller batch sizes and improved generalization is an interesting phenomenon in machine learning. We explain the key mechanisms behind this effect:</p><ol>
<li>
<p><strong>Noise as Regularization</strong><br>
<!-- -->Smaller batches introduce more noise into the gradient updates since each batch provides only a limited view of the overall data distribution. This noise acts as an implicit regularization mechanism, helping the model avoid overfitting to the training data and promoting better generalization to unseen examples.</p>
</li>
<li>
<p><strong>Escaping Sharp Minima</strong><br>
<!-- -->Research suggests that the loss landscape of neural networks contains both &quot;sharp&quot; and &quot;flat&quot; minima. Models that settle in flatter minima tend to generalize better. Smaller batch sizes create noisier updates that help models escape sharp minima and find flatter regions of the loss landscape, which are more robust to small variations in the input data.</p>
</li>
<li>
<p><strong>Exploration of Parameter Space</strong><br>
<!-- -->The added noise from small-batch training encourages broader exploration of the parameter space, making it less likely for the model to get stuck in suboptimal local minima. This wider exploration increases the chances of finding parameter configurations that generalize well.</p>
</li>
<li>
<p><strong>Implicit Learning Rate Adaptation</strong><br>
<!-- -->Smaller batches effectively introduce an adaptive learning rate behavior. The noise in gradient estimates is higher in regions where the loss changes rapidly (sharp minima) and lower in flat regions, naturally pushing optimization toward flatter minima.</p>
</li>
<li>
<p><strong>Diversity of Examples</strong><br>
<!-- -->With smaller batches, the model gets updated more frequently (more iterations per epoch). This means the model &quot;sees&quot; more diverse combinations of training examples during optimization, potentially capturing more nuanced patterns in the data.</p>
</li>
</ol><p>The effect is particularly pronounced in deep neural networks and has been supported by empirical studies showing that models trained with smaller batches often perform better on validation and test data than those trained with larger batches, especially when using the same number of epochs.</p><p>However, it&#x27;s worth noting that extremely small batch sizes can also introduce too much noise, potentially harming convergence. Finding the right batch size usually requires experimentation for your specific task and model architecture.</p></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="epochs">Epochs<a href="#epochs" class="hash-link" aria-label="Direct link to Epochs" title="Direct link to Epochs">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="-introduction">➽ Introduction<a href="#-introduction" class="hash-link" aria-label="Direct link to ➽ Introduction" title="Direct link to ➽ Introduction">​</a></h4>
<p>An <strong>epoch</strong> occurs when a machine learning model has processed every example in the training dataset exactly once. After completing an epoch, the model has had the opportunity to learn from all available training data.</p>
<ul>
<li><strong>Epoch</strong><br>
<!-- -->One complete pass through the entire training dataset</li>
<li><strong>Iteration</strong><br>
<!-- -->One update of the model&#x27;s parameters using a batch of data</li>
</ul>
<p>For example, with a training set of 1,000 examples and a mini-batch size of 100 examples, it takes 10 iterations to complete one epoch.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="-the-role-of-epochs-in-model-training">➽ The Role of Epochs in Model Training<a href="#-the-role-of-epochs-in-model-training" class="hash-link" aria-label="Direct link to ➽ The Role of Epochs in Model Training" title="Direct link to ➽ The Role of Epochs in Model Training">​</a></h4>
<p>Machine learning models typically require <strong>multiple epochs</strong> to effectively learn patterns in the data because:</p>
<ol>
<li>Complex patterns may not be detected in a single pass</li>
<li>The optimization process is iterative and gradual</li>
<li>Weight updates are incremental, requiring repeated exposure to data</li>
</ol>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="-epoch-related-hyperparameters">➽ Epoch-Related Hyperparameters<a href="#-epoch-related-hyperparameters" class="hash-link" aria-label="Direct link to ➽ Epoch-Related Hyperparameters" title="Direct link to ➽ Epoch-Related Hyperparameters">​</a></h4>
<ul>
<li><strong>Number of epochs</strong><br>
<!-- -->How many times the model will process the entire dataset</li>
<li><strong>Batch size</strong><br>
<!-- -->How many samples are processed before updating model parameters</li>
<li><strong>Learning rate</strong><br>
<!-- -->How much to adjust model parameters during each update</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="-batch-sizes-and-parameter-updates">➽ Batch Sizes and Parameter Updates<a href="#-batch-sizes-and-parameter-updates" class="hash-link" aria-label="Direct link to ➽ Batch Sizes and Parameter Updates" title="Direct link to ➽ Batch Sizes and Parameter Updates">​</a></h4>
<p>The following table describes how batch size and epochs relate to the number of times a model updates its parameters.</p>
<table><thead><tr><th>Batch Type</th><th>When Parameters Update</th><th>Example (1,000 examples, 20 epochs)</th></tr></thead><tbody><tr><td>Full Batch</td><td>After processing the entire dataset</td><td>20 updates (once per epoch)</td></tr><tr><td>Stochastic Gradient Descent</td><td>After each individual example</td><td>20,000 updates (examples × epochs)</td></tr><tr><td>Mini-Batch SGD</td><td>After each batch of examples</td><td>200 updates (with batch size 100)</td></tr></tbody></table>
<p><img decoding="async" loading="lazy" alt="My Image" src="/MindMash/assets/images/batch-size-1566637e74cac84116ab3c7e56de1cbd.png" width="1600" height="900" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="-determining-the-optimal-number-of-epochs">➽ Determining the Optimal Number of Epochs<a href="#-determining-the-optimal-number-of-epochs" class="hash-link" aria-label="Direct link to ➽ Determining the Optimal Number of Epochs" title="Direct link to ➽ Determining the Optimal Number of Epochs">​</a></h4>
<p>Here&#x27;s a list of factors influencing Epoch Count:</p>
<ol>
<li><strong>Dataset size</strong><br>
<!-- -->Larger datasets may require fewer epochs</li>
<li><strong>Model complexity</strong><br>
<!-- -->More complex models often need more epochs</li>
<li><strong>Learning rate</strong><br>
<!-- -->Lower learning rates typically require more epochs</li>
<li><strong>Regularization</strong><br>
<!-- -->Stronger regularization may require more epochs</li>
</ol>
<p>And here&#x27;s the signs of appropriate epoch count:</p>
<ul>
<li><strong>Underfitting</strong><br>
<!-- -->Too few epochs, model hasn&#x27;t learned enough</li>
<li><strong>Optimal</strong><br>
<!-- -->Training and validation metrics have stabilized</li>
<li><strong>Overfitting</strong><br>
<!-- -->Too many epochs, model memorizes training data, validation metrics worsen</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="-early-stopping-and-monitoring">➽ Early Stopping and Monitoring<a href="#-early-stopping-and-monitoring" class="hash-link" aria-label="Direct link to ➽ Early Stopping and Monitoring" title="Direct link to ➽ Early Stopping and Monitoring">​</a></h4>
<p><strong>Early Stopping</strong> is a technique to automatically determine the optimal number of epochs by:</p>
<ol>
<li>Monitoring validation metrics during training</li>
<li>Stopping when validation performance begins to degrade</li>
<li>Reverting to the model state with best validation performance</li>
</ol>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>Is Point 3 part of Early Stopping?</div><div class="admonitionContent_BuS1"><p>Point 3 is indeed considered an integral part of the complete early stopping technique, not just an optional follow-up step.</p><p>The core idea of early stopping is to prevent overfitting by halting training when the model begins to learn patterns specific to the training data that don&#x27;t generalize well. However, simply stopping at that point would give us a model that has already begun to overfit.</p><p>So while conceptually we can think of early stopping as just &quot;knowing when to stop&quot;, the complete implementation almost always includes reverting to the best model state as part of the technique itself.</p></div></div>
<p>Some of the most commonly monitored metrics during early stopping include:</p>
<ul>
<li>
<p><strong>Loss curves</strong><br>
<!-- -->These represent the training and validation loss over time. If the validation loss begins to increase while the training loss continues to decrease, it indicates the model is starting to overfit.</p>
</li>
<li>
<p><strong>Accuracy curves</strong><br>
<!-- -->Similar to loss curves, these show the training and validation accuracy over epochs. When the validation accuracy stops improving or starts to drop, it is often a sign to stop training.</p>
</li>
<li>
<p><strong>Other task-specific metrics</strong><br>
<!-- -->Depending on the specific problem, you may also track other metrics like <em>F1-score</em>, <em>precision</em>, <em>recall</em>, or area under the ROC curve (<em>AUC</em>). These are particularly important for imbalanced datasets or when optimization beyond simple accuracy is needed.</p>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="-coding-time">💻 <strong>Coding Time!</strong><a href="#-coding-time" class="hash-link" aria-label="Direct link to -coding-time" title="Direct link to -coding-time">​</a></h2>
<p>Here&#x27;s the link to the interactive <a href="https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_taxi.ipynb?utm_source=mlcc&amp;utm_campaign=colab-external&amp;utm_medium=referral&amp;utm_content=linear_regression#scrollTo=ph0FE7ZxHY36" target="_blank" rel="noopener noreferrer">Google Colab notebook</a>.</p>
<p>We just report here the most important insights.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="dataset-exploration">Dataset Exploration<a href="#dataset-exploration" class="hash-link" aria-label="Direct link to Dataset Exploration" title="Direct link to Dataset Exploration">​</a></h3>
<p>Sometimes it is helpful to <strong>visualize relationships between features</strong> in a dataset; one way to do this is with a <strong>pair plot</strong>. A pair plot generates a grid of pairwise plots to visualize the relationship of each feature with all other features all in one place.</p>
<div class="theme-admonition theme-admonition-note admonition_xJq3 alert alert--secondary"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>Pairplot</div><div class="admonitionContent_BuS1"><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sns</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pairplot</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  training_df</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  x_vars</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;FARE&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;TRIP_MILES&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;TRIP_SECONDS&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  y_vars</span><span class="token operator" style="color:#393A34">=</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;FARE&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;TRIP_MILES&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;TRIP_SECONDS&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><img decoding="async" loading="lazy" alt="My Image" src="/MindMash/assets/images/pairplot-793ee7846a5f60bba135bc0fe8211e6c.png" width="741" height="741" class="img_ev3q"></p></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="scaling">Scaling<a href="#scaling" class="hash-link" aria-label="Direct link to Scaling" title="Direct link to Scaling">​</a></h3>
<p>When training machine learning models with multiple features, it&#x27;s crucial to ensure all numeric values are on a <strong>comparable scale</strong>.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Scaling</div><div class="admonitionContent_BuS1"><p>The notebook discusses a model trained to predict <code>FARE</code> using two features:</p><ul>
<li><code>TRIP_SECONDS</code> (trip duration in seconds)</li>
<li><code>TRIP_MILES</code> (trip distance in miles)</li>
</ul><p>These features have significantly different scales:</p><ul>
<li><code>TRIP_MILES</code> has a mean value of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8.3</mn></mrow><annotation encoding="application/x-tex">8.3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">8.3</span></span></span></span></li>
<li><code>TRIP_SECONDS</code> has a mean value of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1320</mn></mrow><annotation encoding="application/x-tex">1320</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1320</span></span></span></span></li>
</ul><p>This represents a difference of two orders of magnitude, which can cause problems during training.</p><hr><p>The example suggests converting trip duration from seconds to minutes as a simple scaling approach. This brings the features to a more comparable scale:</p><ul>
<li><code>TRIP_MILES</code>: mean of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8.3</mn></mrow><annotation encoding="application/x-tex">8.3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">8.3</span></span></span></span></li>
<li><code>TRIP_MINUTES</code>: mean of approximately <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>22</mn></mrow><annotation encoding="application/x-tex">22</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">22</span></span></span></span> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>1320</mn><mi mathvariant="normal">/</mi><mn>60</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(1320/60)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">1320/60</span><span class="mclose">)</span></span></span></span></li>
</ul></div></div>
<p>Note: while we demonstrated a simple unit conversion approach, more sophisticated scaling techniques will be covered in subsequent modules.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="-problems-caused-by-unscaled-features">➽ Problems Caused by Unscaled Features<a href="#-problems-caused-by-unscaled-features" class="hash-link" aria-label="Direct link to ➽ Problems Caused by Unscaled Features" title="Direct link to ➽ Problems Caused by Unscaled Features">​</a></h4>
<p>In linear regression using gradient descent optimization:</p>
<ul>
<li>The gradients of the cost function with respect to each feature are proportional to both the feature values and their errors.</li>
<li>Features with larger values produce larger gradients.</li>
<li>This causes the optimization algorithm to &quot;step&quot; farther along dimensions with larger scales.</li>
<li>As a result, the algorithm may oscillate or zigzag through the error space, slowing convergence.</li>
</ul>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>A concrete example</div><div class="admonitionContent_BuS1"><p>Let&#x27;s focus on a simple example with linear regression to show how unscaled features can cause problems during gradient descent optimization.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="example-setup">Example Setup<a href="#example-setup" class="hash-link" aria-label="Direct link to Example Setup" title="Direct link to Example Setup">​</a></h4><p>Let&#x27;s consider a linear regression problem with a bias term and two features:</p><ul>
<li>Feature 1: <strong>Income in dollars</strong> (values around <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50000</mn></mrow><annotation encoding="application/x-tex">50000</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">50000</span></span></span></span>)</li>
<li>Feature 2: <strong>Age in years</strong> (values around <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>30</mn></mrow><annotation encoding="application/x-tex">30</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">30</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>40</mn></mrow><annotation encoding="application/x-tex">40</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">40</span></span></span></span>)</li>
</ul><p>We&#x27;re trying to predict <strong>house prices</strong> (in thousands of dollars).</p><p>Our model is: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><msub><mi>w</mi><mn>0</mn></msub><mo>+</mo><msub><mi>w</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>w</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">y = w₀ + w₁x₁ + w₂x₂</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></p><ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">w₀</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> is the bias term</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">w₁</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> is the weight for income (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">x₁</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>)</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">w₂</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> is the weight for age (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">x₂</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>)</li>
</ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="the-problem-visualization">The Problem Visualization<a href="#the-problem-visualization" class="hash-link" aria-label="Direct link to The Problem Visualization" title="Direct link to The Problem Visualization">​</a></h4><p>Let&#x27;s visualize what happens during gradient descent with these unscaled features:</p><ol>
<li>
<p><strong>Gradient Calculation</strong>: for each weight, the gradient is computed as:</p>
<ul>
<li>For <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">w₀</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∂</mi><mi>J</mi><mi mathvariant="normal">/</mi><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mn>0</mn></msub><mo>=</mo><mi mathvariant="normal">Σ</mi><mo stretchy="false">(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>−</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">∂J/∂w₀ = Σ(ŷ - y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord mathnormal" style="margin-right:0.09618em">J</span><span class="mord">/</span><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">Σ</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.1944em"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mclose">)</span></span></span></span></li>
<li>For <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">w₁</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∂</mi><mi>J</mi><mi mathvariant="normal">/</mi><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mn>1</mn></msub><mo>=</mo><mi mathvariant="normal">Σ</mi><mo stretchy="false">(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>−</mo><mi>y</mi><mo stretchy="false">)</mo><mo>∗</mo><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">∂J/∂w₁ = Σ(ŷ - y) * x₁</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord mathnormal" style="margin-right:0.09618em">J</span><span class="mord">/</span><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">Σ</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.1944em"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></li>
<li>For <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">w₂</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∂</mi><mi>J</mi><mi mathvariant="normal">/</mi><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mn>2</mn></msub><mo>=</mo><mi mathvariant="normal">Σ</mi><mo stretchy="false">(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>−</mo><mi>y</mi><mo stretchy="false">)</mo><mo>∗</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">∂J/∂w₂ = Σ(ŷ - y) * x₂</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord mathnormal" style="margin-right:0.09618em">J</span><span class="mord">/</span><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">Σ</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.1944em"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></li>
</ul>
</li>
<li>
<p><strong>Impact of Feature Scale</strong>:</p>
<ul>
<li>Income (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">x₁</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>) has values around <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50000</mn></mrow><annotation encoding="application/x-tex">50000</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">50000</span></span></span></span>, so <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∂</mi><mi>J</mi><mi mathvariant="normal">/</mi><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">∂J/∂w₁</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord mathnormal" style="margin-right:0.09618em">J</span><span class="mord">/</span><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> will be ~ <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50000</mn></mrow><annotation encoding="application/x-tex">50000</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">50000</span></span></span></span> times larger than the gradient for the bias</li>
<li>Age (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">x₂</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>) has values around <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>35</mn></mrow><annotation encoding="application/x-tex">35</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">35</span></span></span></span>, so <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∂</mi><mi>J</mi><mi mathvariant="normal">/</mi><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">∂J/∂w₂</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord mathnormal" style="margin-right:0.09618em">J</span><span class="mord">/</span><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> will be ~ <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>35</mn></mrow><annotation encoding="application/x-tex">35</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">35</span></span></span></span> times larger than the bias gradient</li>
</ul>
</li>
<li>
<p><strong>Concrete Example</strong>:
Let&#x27;s say we have a small dataset:</p>
<table><thead><tr><th>Income (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">x₁</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>)</th><th>Age (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">x₂</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>)</th><th>House Price (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span></span></span>)</th></tr></thead><tbody><tr><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>52000</mn></mrow><annotation encoding="application/x-tex">52000</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">52000</span></span></span></span></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>35</mn></mrow><annotation encoding="application/x-tex">35</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">35</span></span></span></span></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>250</mn></mrow><annotation encoding="application/x-tex">250</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">250</span></span></span></span></td></tr><tr><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>48000</mn></mrow><annotation encoding="application/x-tex">48000</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">48000</span></span></span></span></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>42</mn></mrow><annotation encoding="application/x-tex">42</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">42</span></span></span></span></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>230</mn></mrow><annotation encoding="application/x-tex">230</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">230</span></span></span></span></td></tr><tr><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>65000</mn></mrow><annotation encoding="application/x-tex">65000</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">65000</span></span></span></span></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>28</mn></mrow><annotation encoding="application/x-tex">28</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">28</span></span></span></span></td><td><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>285</mn></mrow><annotation encoding="application/x-tex">285</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">285</span></span></span></span></td></tr></tbody></table>
<p>If we start with all weights at zero: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>0</mn></msub><mo>=</mo><mn>0</mn><mo separator="true">,</mo><msub><mi>w</mi><mn>1</mn></msub><mo>=</mo><mn>0</mn><mo separator="true">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">w₀ = 0, w₁ = 0, w₂ = 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8389em;vertical-align:-0.1944em"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8389em;vertical-align:-0.1944em"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0</span></span></span></span></p>
<p>Let&#x27;s compute the gradients for a single step with learning rate <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.0001</mn></mrow><annotation encoding="application/x-tex">α = 0.0001</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.0001</span></span></span></span>:</p>
<p>For the first data point:</p>
<ul>
<li>
<p>Prediction<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>=</mo><mn>0</mn><mo>+</mo><mn>0</mn><mo stretchy="false">(</mo><mn>52000</mn><mo stretchy="false">)</mo><mo>+</mo><mn>0</mn><mo stretchy="false">(</mo><mn>35</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">ŷ = 0 + 0(52000) + 0(35) = 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.1944em"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">0</span><span class="mopen">(</span><span class="mord">52000</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">0</span><span class="mopen">(</span><span class="mord">35</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0</span></span></span></span></p>
</li>
<li>
<p>Error<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>−</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mn>0</mn><mo>−</mo><mn>250</mn><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mn>250</mn></mrow><annotation encoding="application/x-tex">(ŷ - y) = (0 - 250) = -250</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="accent-body" style="left:-0.1944em"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">250</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">250</span></span></span></span></p>
</li>
<li>
<p>Gradients:</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∂</mi><mi>J</mi><mi mathvariant="normal">/</mi><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mn>0</mn></msub><mo>=</mo><mo>−</mo><mn>250</mn></mrow><annotation encoding="application/x-tex">∂J/∂w₀ = -250</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord mathnormal" style="margin-right:0.09618em">J</span><span class="mord">/</span><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">250</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∂</mi><mi>J</mi><mi mathvariant="normal">/</mi><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mn>1</mn></msub><mo>=</mo><mo>−</mo><mn>250</mn><mo>∗</mo><mn>52000</mn><mo>=</mo><mo>−</mo><mn>13000000</mn></mrow><annotation encoding="application/x-tex">∂J/∂w₁ = -250 * 52000 = -13000000</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord mathnormal" style="margin-right:0.09618em">J</span><span class="mord">/</span><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">250</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">52000</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">13000000</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∂</mi><mi>J</mi><mi mathvariant="normal">/</mi><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mn>2</mn></msub><mo>=</mo><mo>−</mo><mn>250</mn><mo>∗</mo><mn>35</mn><mo>=</mo><mo>−</mo><mn>8750</mn></mrow><annotation encoding="application/x-tex">∂J/∂w₂ = -250 * 35 = -8750</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord mathnormal" style="margin-right:0.09618em">J</span><span class="mord">/</span><span class="mord" style="margin-right:0.05556em">∂</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">250</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">35</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">8750</span></span></span></span></li>
</ul>
</li>
</ul>
<p>After one update:</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>0</mn></msub><mo>=</mo><mn>0</mn><mo>−</mo><mn>0.0001</mn><mo>∗</mo><mo stretchy="false">(</mo><mo>−</mo><mn>250</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0.025</mn></mrow><annotation encoding="application/x-tex">w₀ = 0 - 0.0001 * (-250) = 0.025</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.0001</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">250</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.025</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo>=</mo><mn>0</mn><mo>−</mo><mn>0.0001</mn><mo>∗</mo><mo stretchy="false">(</mo><mo>−</mo><mn>13000000</mn><mo stretchy="false">)</mo><mo>=</mo><mn>1300</mn></mrow><annotation encoding="application/x-tex">w₁ = 0 - 0.0001 * (-13000000) = 1300</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.0001</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">13000000</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1300</span></span></span></span></li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>2</mn></msub><mo>=</mo><mn>0</mn><mo>−</mo><mn>0.0001</mn><mo>∗</mo><mo stretchy="false">(</mo><mo>−</mo><mn>8750</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0.875</mn></mrow><annotation encoding="application/x-tex">w₂ = 0 - 0.0001 * (-8750) = 0.875</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.0001</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">8750</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.875</span></span></span></span></li>
</ul>
</li>
<li>
<p><strong>The Problem</strong></p>
<ul>
<li>The weight for income (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">w₁</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>) changed dramatically (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>→</mo><mn>1300</mn></mrow><annotation encoding="application/x-tex">0 → 1300</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1300</span></span></span></span>)</li>
<li>The weight for age (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">w₂</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>) had a moderate change (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>→</mo><mn>0.875</mn></mrow><annotation encoding="application/x-tex">0 → 0.875</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.875</span></span></span></span>)</li>
<li>The bias term barely moved (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>→</mo><mn>0.025</mn></mrow><annotation encoding="application/x-tex">0 → 0.025</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.025</span></span></span></span>)</li>
</ul>
</li>
</ol><p>This causes two major issues:</p><ol>
<li>
<p><strong>Zigzagging</strong><br>
<!-- -->As we continue optimization, we&#x27;ll take huge steps in the income direction and tiny steps in the bias direction, causing an inefficient zigzag path through the parameter space.</p>
</li>
<li>
<p><strong>Learning Rate Dilemma</strong></p>
<ul>
<li>If we use a small learning rate to prevent overshooting in the income dimension, we&#x27;ll make painfully slow progress in the bias dimension</li>
<li>If we use a larger learning rate to make reasonable progress in the bias dimension, we&#x27;ll cause wild oscillations in the income dimension</li>
</ul>
</li>
</ol><p>This is why feature scaling (like standardization or normalization) is crucial for efficient gradient descent. It ensures all features contribute proportionally to the parameter updates.</p></div></div></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/MindMash/docs/notes/Information Technology/Artificial Intelligence/👨🏻‍🏫 Google - 01 - Intro to ML/google-model-1"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">🧪 LayoutLMv3</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/MindMash/docs/notes/Information Technology/Artificial Intelligence/👨🏻‍🏫 Google - 02 - ML/google-2-unit-addtional-1"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">📖 Gradient Descent</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#️-useful-materials" class="table-of-contents__link toc-highlight">➡️ <strong>Useful Materials</strong></a><ul><li><a href="#original-source" class="table-of-contents__link toc-highlight">Original Source</a></li></ul></li><li><a href="#1️⃣-introduction" class="table-of-contents__link toc-highlight">1️⃣ <strong>Introduction</strong></a></li><li><a href="#2️⃣-example-fuel-efficiency" class="table-of-contents__link toc-highlight">2️⃣ <strong>Example: Fuel Efficiency</strong></a><ul><li><a href="#single-feature" class="table-of-contents__link toc-highlight">Single Feature</a></li><li><a href="#multiple-features" class="table-of-contents__link toc-highlight">Multiple Features</a></li></ul></li><li><a href="#3️⃣-loss" class="table-of-contents__link toc-highlight">3️⃣ <strong>Loss</strong></a><ul><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#distance-of-loss" class="table-of-contents__link toc-highlight">Distance of loss</a></li><li><a href="#types-of-loss" class="table-of-contents__link toc-highlight">Types of loss</a></li><li><a href="#choosing-a-loss" class="table-of-contents__link toc-highlight">Choosing a loss</a></li></ul></li><li><a href="#4️⃣-gradient-descent" class="table-of-contents__link toc-highlight">4️⃣ <strong>Gradient Descent</strong></a></li><li><a href="#5️⃣-model-convergence-and-loss-curves" class="table-of-contents__link toc-highlight">5️⃣ <strong>Model convergence and loss curves</strong></a><ul><li><a href="#interpreting-the-loss-curve" class="table-of-contents__link toc-highlight">Interpreting the Loss Curve</a></li><li><a href="#snapshots-of-model-training" class="table-of-contents__link toc-highlight">Snapshots of Model Training</a></li><li><a href="#factors-affecting-convergence" class="table-of-contents__link toc-highlight">Factors Affecting Convergence</a></li><li><a href="#convergence-and-convex-functions" class="table-of-contents__link toc-highlight">Convergence and convex functions</a></li></ul></li><li><a href="#6️⃣-hyperparameters" class="table-of-contents__link toc-highlight">6️⃣ <strong>Hyperparameters</strong></a><ul><li><a href="#introduction-1" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#parameters-vs-hyperparameters" class="table-of-contents__link toc-highlight">Parameters vs. Hyperparameters</a></li><li><a href="#learning-rate" class="table-of-contents__link toc-highlight">Learning Rate</a></li><li><a href="#batch-size" class="table-of-contents__link toc-highlight">Batch Size</a></li><li><a href="#epochs" class="table-of-contents__link toc-highlight">Epochs</a></li></ul></li><li><a href="#-coding-time" class="table-of-contents__link toc-highlight">💻 <strong>Coding Time!</strong></a><ul><li><a href="#dataset-exploration" class="table-of-contents__link toc-highlight">Dataset Exploration</a></li><li><a href="#scaling" class="table-of-contents__link toc-highlight">Scaling</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">My Links</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://danielepassabi.github.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item">My Portfolio<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.linkedin.com/in/daniele-passabi/" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">(I do not really need a) Copyright © 2025 MindMash, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>